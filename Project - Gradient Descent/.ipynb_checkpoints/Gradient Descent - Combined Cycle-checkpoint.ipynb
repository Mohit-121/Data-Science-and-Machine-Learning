{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_cost(X,Y,m,c):\n",
    "    M = len(X)\n",
    "    total_cost = 0\n",
    "    for i in range(M):\n",
    "        x = X[i,:]\n",
    "        y = Y[i]\n",
    "        total_cost += (1/M) * ((y - (m * x).sum() - c)**2)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(Y_true,Y_pred):\n",
    "    u = ((Y_true - Y_pred)**2).sum()\n",
    "    v = ((Y_true - Y_true.mean())**2).sum()\n",
    "    return 1 - u/v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_step_gradient_descent(X,Y,learning_rate,m,c):\n",
    "    N = X.shape[1]\n",
    "    m_slope, c_slope = np.zeros(N), 0\n",
    "    M = len(X)\n",
    "    for i in range(M):\n",
    "        x = X[i,:]\n",
    "        y = Y[i]\n",
    "        for j in range(N):\n",
    "            m_slope[j] += (-2/M) * (y - (m*x).sum() - c)*x[j]\n",
    "        c_slope += (-2/M) * (y - (m*x).sum() - c)\n",
    "    new_m = m - learning_rate*m_slope\n",
    "    new_c = c - learning_rate*c_slope\n",
    "    return new_m,new_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Gradient Descent\n",
    "def generic_gradient_descent(X,Y,learning_rate,num_iterations):\n",
    "    N = X.shape[1]\n",
    "    m, c = np.zeros(N) , 0\n",
    "    for i in range(num_iterations):\n",
    "        m, c = generic_step_gradient_descent(X,Y,learning_rate,m,c)\n",
    "        if(i>0):\n",
    "            print(i,\"Cost: \", generic_cost(X,Y,m,c))\n",
    "    return m,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding all the 2d features columns and checking the score\n",
    "def add_feature(dataset):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df1 = df.copy()\n",
    "    l = dataset.shape[1]\n",
    "    c = l\n",
    "    s = set()\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            c_name = str(i)+\"_\"+str(j)\n",
    "            if(i<j):\n",
    "                c_name = str(j)+\"_\"+str(i)\n",
    "            if(c_name not in s):\n",
    "                df1[c] = df[i] * df[j]\n",
    "                s.add(c_name)\n",
    "                c+=1\n",
    "    X2 = df1.values\n",
    "    return X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_generic():\n",
    "    # getting the training data\n",
    "    dataset = np.genfromtxt(\"0000000000002419_training_ccpp_x_y_train.csv\",delimiter = \",\")\n",
    "    X_train = np.array(dataset[:,:-1])\n",
    "#     X_train = add_feature(X_train)\n",
    "    Y_train = np.array(dataset[:,-1])\n",
    "    \n",
    "    # applying feature scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    print(\"Shape\",X_train.shape)\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    \n",
    "    # getting the test data\n",
    "    X_test = np.genfromtxt(\"0000000000002419_test_ccpp_x_test.csv\",delimiter = \",\")\n",
    "#     X_test = add_feature(X_test)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # defining parameters and calling calling gradient descent function\n",
    "    learning_rate = 0.2\n",
    "    num_iterations = 100\n",
    "    m, c = generic_gradient_descent(X_train,Y_train,learning_rate,num_iterations)\n",
    "    \n",
    "    Y_train_pred = (m * X_train).sum(axis=1) + c\n",
    "    Y_test_pred = (m * X_test).sum(axis=1) + c\n",
    "    print(\"Score is: \",score(Y_train,Y_train_pred))\n",
    "    np.savetxt(\"Y_pred1.csv\",Y_test_pred,delimiter = \",\",fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (7176, 4)\n",
      "1 Cost:  26799.242503792175\n",
      "2 Cost:  9667.643213351957\n",
      "3 Cost:  3499.3247676562505\n",
      "4 Cost:  1278.0283196819855\n",
      "5 Cost:  477.8160269712305\n",
      "6 Cost:  189.29840013368795\n",
      "7 Cost:  85.06306229647086\n",
      "8 Cost:  47.221331673237046\n",
      "9 Cost:  33.32033677022838\n",
      "10 Cost:  28.068569379733468\n",
      "11 Cost:  25.955379768322796\n",
      "12 Cost:  24.992956681736715\n",
      "13 Cost:  24.462804989575602\n",
      "14 Cost:  24.104087477563205\n",
      "15 Cost:  23.821187041728113\n",
      "16 Cost:  23.578279429707152\n",
      "17 Cost:  23.361285613198984\n",
      "18 Cost:  23.164115096572573\n",
      "19 Cost:  22.983675064232603\n",
      "20 Cost:  22.818048282043936\n",
      "21 Cost:  22.66581987471472\n",
      "22 Cost:  22.525822801627825\n",
      "23 Cost:  22.397037310565377\n",
      "24 Cost:  22.278547925441632\n",
      "25 Cost:  22.169522539596684\n",
      "26 Cost:  22.069200418735647\n",
      "27 Cost:  21.976884085133445\n",
      "28 Cost:  21.891933095748453\n",
      "29 Cost:  21.813758883785773\n",
      "30 Cost:  21.74182028824115\n",
      "31 Cost:  21.675619583764707\n",
      "32 Cost:  21.61469890594002\n",
      "33 Cost:  21.558637006529448\n",
      "34 Cost:  21.50704629373865\n",
      "35 Cost:  21.459570124139383\n",
      "36 Cost:  21.415880319954937\n",
      "37 Cost:  21.375674890025685\n",
      "38 Cost:  21.33867593598674\n",
      "39 Cost:  21.304627727531148\n",
      "40 Cost:  21.273294932457944\n",
      "41 Cost:  21.24446098865873\n",
      "42 Cost:  21.217926606418857\n",
      "43 Cost:  21.193508390455534\n",
      "44 Cost:  21.171037572027647\n",
      "45 Cost:  21.150358842272176\n",
      "46 Cost:  21.13132927865048\n",
      "47 Cost:  21.113817357052486\n",
      "48 Cost:  21.09770204271273\n",
      "49 Cost:  21.082871953642524\n",
      "50 Cost:  21.069224590789197\n",
      "51 Cost:  21.05666562959698\n",
      "52 Cost:  21.045108268070997\n",
      "53 Cost:  21.034472626835843\n",
      "54 Cost:  21.02468519704281\n",
      "55 Cost:  21.015678332307413\n",
      "56 Cost:  21.00738978116694\n",
      "57 Cost:  20.999762256824265\n",
      "58 Cost:  20.99274304120805\n",
      "59 Cost:  20.986283620607534\n",
      "60 Cost:  20.980339350367466\n",
      "61 Cost:  20.97486914632417\n",
      "62 Cost:  20.969835200849168\n",
      "63 Cost:  20.965202721540596\n",
      "64 Cost:  20.96093969075244\n",
      "65 Cost:  20.95701664430351\n",
      "66 Cost:  20.953406467834387\n",
      "67 Cost:  20.950084209403535\n",
      "68 Cost:  20.947026907031738\n",
      "69 Cost:  20.94421342999911\n",
      "70 Cost:  20.941624332798128\n",
      "71 Cost:  20.93924172073532\n",
      "72 Cost:  20.937049126251157\n",
      "73 Cost:  20.935031395103447\n",
      "74 Cost:  20.933174581628084\n",
      "75 Cost:  20.93146585235249\n",
      "76 Cost:  20.92989339729653\n",
      "77 Cost:  20.92844634834707\n",
      "78 Cost:  20.927114704142742\n",
      "79 Cost:  20.92588926094833\n",
      "80 Cost:  20.924761549043115\n",
      "81 Cost:  20.923723774181802\n",
      "82 Cost:  20.922768763724026\n",
      "83 Cost:  20.921889917060557\n",
      "84 Cost:  20.921081159992205\n",
      "85 Cost:  20.92033690274845\n",
      "86 Cost:  20.919652001352517\n",
      "87 Cost:  20.919021722069445\n",
      "88 Cost:  20.918441708687805\n",
      "89 Cost:  20.9179079524122\n",
      "90 Cost:  20.917416764155334\n",
      "91 Cost:  20.916964749041504\n",
      "92 Cost:  20.9165487829424\n",
      "93 Cost:  20.916165990884657\n",
      "94 Cost:  20.915813727179003\n",
      "95 Cost:  20.915489557134684\n",
      "96 Cost:  20.91519124023184\n",
      "97 Cost:  20.914916714636348\n",
      "98 Cost:  20.91466408294852\n",
      "99 Cost:  20.914431599090356\n",
      "Score is:  0.9287540616183254\n"
     ]
    }
   ],
   "source": [
    "run_generic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
