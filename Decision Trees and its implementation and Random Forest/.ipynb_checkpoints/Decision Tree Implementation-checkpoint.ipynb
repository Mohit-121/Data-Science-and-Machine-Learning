{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TreeNode to build the tree\n",
    "class TreeNode:\n",
    "    def __init__(self, entropy, level, prediction, splitFeature = \"\", isLeaf = False):\n",
    "        self.level = level\n",
    "        self.entropy = entropy\n",
    "        self.prediction = prediction\n",
    "        self.isLeaf = isLeaf\n",
    "        self.splitFeature = splitFeature\n",
    "        \n",
    "    def predict(self):\n",
    "        return self.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_entropy(pi_count):\n",
    "    '''\n",
    "        returns calculated entropy\n",
    "    '''\n",
    "    ans = 0\n",
    "    pi_sum = sum(pi_count)\n",
    "    for pi in pi_count:\n",
    "        ans += (pi/pi_sum)*math.log2(pi/pi_sum)\n",
    "    if(ans==0):\n",
    "        return ans\n",
    "    return -ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gain_ratio(X,Y,f,f_values,info_org):\n",
    "    \n",
    "    '''\n",
    "        returns the splits made if split with feature(f) \n",
    "        and corresponding gain ratio of the feature(f)\n",
    "    '''\n",
    "    \n",
    "    d_sum = len(Y)\n",
    "    info_f,split_info_f = 0,0\n",
    "    splits_X,splits_Y = {},{}\n",
    "    for fval in f_values:\n",
    "        X1 = X[X[f]==fval]   # finding the X corresponding to fval of feature f\n",
    "        Y1 = Y[X1.index]     # finding the Y corresponding to fval of feature f\n",
    "        splits_X[fval] = X1  # Adding X and Y splits so that they can be recursively called\n",
    "        splits_Y[fval] = Y1\n",
    "\n",
    "        pi_count = list(Y1.value_counts())   # count of Y values after splitting with feature f for value fval\n",
    "        info_f += (len(Y1)/d_sum)*cal_entropy(pi_count)   # Information required for the same\n",
    "        split_info_f -= (len(Y1)/d_sum)*math.log2(len(Y1)/d_sum)  # Split info for the same                                      \n",
    "\n",
    "    info_gain_f = info_org - info_f         # Info_gain_feature = Orignal_Info - Info. after split at f\n",
    "    gain_ratio_f = info_gain_f/split_info_f\n",
    "    \n",
    "    return splits_X,splits_Y,gain_ratio_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_implementation(X,Y,features,level):\n",
    "    '''\n",
    "        return the root of the decision tree built\n",
    "    '''\n",
    "    # Finding different values in each node\n",
    "    pi_count = list(Y.value_counts())\n",
    "    pi_index = list(Y.value_counts().index)\n",
    "    info_org = cal_entropy(pi_count)\n",
    "    \n",
    "    node_result = Y.value_counts().idxmax()\n",
    "    \n",
    "    print(\"Level is: \",level)\n",
    "    for i in range(len(pi_count)):\n",
    "        print(\"Count of\",pi_index[i],\"is:\",pi_count[i])\n",
    "    print(\"Current Entropy is:\",info_org)\n",
    "    \n",
    "    # Base condition for decision trees\n",
    "    if(len(pi_count)==1 or len(features)==0):\n",
    "        root = TreeNode(info_org, level, node_result, isLeaf = True)  # creating leaf node\n",
    "        print(\"Reached Leaf Node\\n\")\n",
    "        return root\n",
    "    \n",
    "    max_gain_ratio = 0\n",
    "    split_feature = \"\"\n",
    "    split_final_X, split_final_Y = {}, {}\n",
    "    for f in features:\n",
    "        f_values = X[f].unique()\n",
    "        splits_X,splits_Y,gain_ratio_f = find_gain_ratio(X,Y,f,f_values,info_org)\n",
    "        \n",
    "        if(gain_ratio_f > max_gain_ratio):\n",
    "            max_gain_ratio = gain_ratio_f\n",
    "            split_feature = f\n",
    "            split_final_X = splits_X\n",
    "            split_final_Y = splits_Y\n",
    "            \n",
    "    print(\"Splitting on feature\",split_feature,\"with gain ratio\",max_gain_ratio,\"\\n\")\n",
    "    \n",
    "    new_feature = features.copy()\n",
    "    new_feature.remove(split_feature)    # removing the feature\n",
    "    \n",
    "    # creating the tree Node\n",
    "    root = TreeNode(info_org, level, node_result, split_feature)\n",
    "    root.children = {}\n",
    "    \n",
    "    for split in split_final_X:\n",
    "        # Recursively calling on all the splits and adding those splits to the children\n",
    "        root.children[split] = decision_tree_implementation(split_final_X[split],split_final_Y[split],new_feature,level+1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(root, x):\n",
    "    '''\n",
    "        return the prediction for a single row\n",
    "    '''\n",
    "    if(root.isLeaf):             # If it is a pure node return the prediction\n",
    "        return root.predict()\n",
    "    \n",
    "    f = root.splitFeature\n",
    "    if(x[f] not in root.children):  # If the feature is not present in that node return the prediction(majority) of that node\n",
    "        return root.predict()\n",
    "    return helper(root.children[x[f]],x)   # Recursively call on the child node for the feature\n",
    "\n",
    "def predict(root,X):\n",
    "    '''\n",
    "        return the prediction array for a given X\n",
    "    '''\n",
    "    prediction = []\n",
    "    for i in range(len(X)):\n",
    "        p = helper(root,X.iloc[i,:])   # helper to find prediction of ith row\n",
    "        prediction.append(p)\n",
    "    return np.array(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(x,v1,v2,v3):\n",
    "    '''\n",
    "        returns labels\n",
    "    '''\n",
    "    if x<=v1:\n",
    "        return 'a'\n",
    "    elif x>v1 and x<=v2:\n",
    "        return 'b'\n",
    "    elif x>v2 and x<=v3:\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'd'\n",
    "    \n",
    "def preprocess(X):\n",
    "    '''\n",
    "        returns labelled data based on values <=25%, <=50%, <=75% and >75%\n",
    "    '''\n",
    "    v1,v2,v3 = X.quantile(0.25),X.quantile(0.5),X.quantile(0.75)\n",
    "    return X.apply(function1,args = [v1,v2,v3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree in Depth-First Manner\n",
      "Level is:  0\n",
      "Count of 2 is: 41\n",
      "Count of 0 is: 37\n",
      "Count of 1 is: 34\n",
      "Current Entropy is: 1.58071971384221\n",
      "Splitting on feature petal length (cm)_labelled with gain ratio 0.6008507954091064 \n",
      "\n",
      "Level is:  1\n",
      "Count of 1 is: 15\n",
      "Count of 2 is: 13\n",
      "Current Entropy is: 0.996316519558962\n",
      "Splitting on feature petal width (cm)_labelled with gain ratio 0.266575203380578 \n",
      "\n",
      "Level is:  2\n",
      "Count of 1 is: 12\n",
      "Count of 2 is: 8\n",
      "Current Entropy is: 0.9709505944546686\n",
      "Splitting on feature sepal length (cm)_labelled with gain ratio 0.2836846600308684 \n",
      "\n",
      "Level is:  3\n",
      "Count of 1 is: 6\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  3\n",
      "Count of 2 is: 7\n",
      "Count of 1 is: 6\n",
      "Current Entropy is: 0.9957274520849256\n",
      "Splitting on feature sepal width (cm)_labelled with gain ratio 0.13702530817459677 \n",
      "\n",
      "Level is:  4\n",
      "Count of 2 is: 4\n",
      "Count of 1 is: 3\n",
      "Current Entropy is: 0.9852281360342516\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  4\n",
      "Count of 1 is: 1\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  4\n",
      "Count of 2 is: 3\n",
      "Count of 1 is: 1\n",
      "Current Entropy is: 0.8112781244591328\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  4\n",
      "Count of 1 is: 1\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  3\n",
      "Count of 2 is: 1\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  2\n",
      "Count of 1 is: 3\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  2\n",
      "Count of 2 is: 5\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  1\n",
      "Count of 2 is: 28\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  1\n",
      "Count of 0 is: 33\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  1\n",
      "Count of 1 is: 19\n",
      "Count of 0 is: 4\n",
      "Current Entropy is: 0.6665783579949205\n",
      "Splitting on feature petal width (cm)_labelled with gain ratio 0.4390566129108003 \n",
      "\n",
      "Level is:  2\n",
      "Count of 0 is: 3\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  2\n",
      "Count of 1 is: 2\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  2\n",
      "Count of 1 is: 17\n",
      "Count of 0 is: 1\n",
      "Current Entropy is: 0.3095434291503252\n",
      "Splitting on feature sepal width (cm)_labelled with gain ratio 0.2592113863088289 \n",
      "\n",
      "Level is:  3\n",
      "Count of 1 is: 6\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  3\n",
      "Count of 1 is: 11\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  3\n",
      "Count of 0 is: 1\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris.data,columns = iris.feature_names)  # converting into Pandas dataFrame\n",
    "\n",
    "# Adding the labelled data to make it discrete and removing the continuous data\n",
    "for i in X.columns:\n",
    "    X[i+'_labelled'] = preprocess(X[i])\n",
    "    X.drop(i,inplace = True, axis = 1)\n",
    "    \n",
    "Y = pd.DataFrame(iris.target).iloc[:,0]      # converting the output in Pandas dataSeries\n",
    "labels = iris.target_names\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state = 1)\n",
    "# calling decision_tree_implementation on x_train and y_train\n",
    "print(\"Tree in Depth-First Manner\")\n",
    "root = decision_tree_implementation(x_train,y_train,list(X.columns),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values of on x_test\n",
      "[0 1 1 0 2 1 2 1 0 2 1 1 2 1 2 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2 2 2 1 2 2 0 1\n",
      " 0]\n",
      "Confusion Matrix on Training Data\n",
      "[[37  0  0]\n",
      " [ 0 30  4]\n",
      " [ 0  0 41]]\n",
      "Confusion Matrix on Testing Data\n",
      "[[11  2  0]\n",
      " [ 0 14  2]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the performance of the tree built on training and testing data\n",
    "\n",
    "y_train_pred = predict(root, x_train)   # getting training predictions\n",
    "y_test_pred = predict(root,x_test)   # getting testing predictions\n",
    "print(\"Predicted values of on x_test\")\n",
    "print(y_test_pred)\n",
    "train_confusion_matrix = confusion_matrix(y_train,y_train_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test,y_test_pred)\n",
    "print(\"Confusion Matrix on Training Data\")\n",
    "print(train_confusion_matrix)\n",
    "print(\"Confusion Matrix on Testing Data\")\n",
    "print(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level is:  0\n",
      "Count of True is: 3\n",
      "Count of False is: 1\n",
      "Current Entropy is: 0.8112781244591328\n",
      "Splitting on feature X1 with gain ratio 0.31127812445913283 \n",
      "\n",
      "Level is:  1\n",
      "Count of True is: 2\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  1\n",
      "Count of True is: 1\n",
      "Count of False is: 1\n",
      "Current Entropy is: 1.0\n",
      "Splitting on feature X2 with gain ratio 1.0 \n",
      "\n",
      "Level is:  2\n",
      "Count of True is: 1\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level is:  2\n",
      "Count of False is: 1\n",
      "Current Entropy is: 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "[[1 0]\n",
      " [0 3]]\n"
     ]
    }
   ],
   "source": [
    "# Implementation of the same decision tree built on OR function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "mat = {\n",
    "    \"X1\" : [True,False,True,False],\n",
    "    \"X2\" : [True,True,False,False],\n",
    "    \"Y\" : [True,True,True,False]\n",
    "}\n",
    "df = pd.DataFrame(mat)\n",
    "features = list(df.iloc[:,:-1].columns)\n",
    "X = df.iloc[:,:-1]\n",
    "Y = df.iloc[:,-1]\n",
    "root = decision_tree_implementation(X,Y,features,0)\n",
    "\n",
    "y_pred = predict(root,X)\n",
    "print(confusion_matrix(Y,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
